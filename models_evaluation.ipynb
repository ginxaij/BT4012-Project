{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb5c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9073146a",
   "metadata": {},
   "source": [
    "### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de31a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/processed/train.csv\")\n",
    "test = pd.read_csv(\"./data/processed/test.csv\")\n",
    "\n",
    "X_train = train.drop(columns=[\"review_flagged\"])\n",
    "y_train = train[\"review_flagged\"]\n",
    "\n",
    "X_test = test.drop(columns=[\"review_flagged\"])\n",
    "y_test = test[\"review_flagged\"]\n",
    "\n",
    "# Replace inf and -inf with NaN\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Replace NaN with 0\n",
    "X_train = X_train.fillna(0)\n",
    "X_test  = X_test.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87463c8",
   "metadata": {},
   "source": [
    "### Model Evaluation Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a7e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Evaluates a binary classifier using appropriate metrics.\n",
    "    \"\"\"\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    results = {\n",
    "        \"Model\": name,\n",
    "        \"ROC-AUC\": roc_auc_score(y_true, y_prob),\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776478f",
   "metadata": {},
   "source": [
    "### Model Training + Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf94144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. BASELINE MODEL (predict prob = 0.5)\n",
    "all_results = []\n",
    "y_prob_baseline = np.full_like(y_test, 0.5, dtype=float)\n",
    "\n",
    "baseline_result = evaluate_model(\"Baseline (0.5 prob)\", y_test, y_prob_baseline)\n",
    "all_results.append(baseline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c74fb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LOGISTIC REGRESSION\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV predictions for train\n",
    "logreg_cv_pred = cross_val_predict(\n",
    "    logreg_pipeline, X_train, y_train,\n",
    "    cv=cv, method=\"predict_proba\"\n",
    ")[:, 1]\n",
    "\n",
    "# Train on full training set\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test set prediction\n",
    "y_prob_logreg = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "logreg_result = evaluate_model(\"Logistic Regression (CV)\", y_test, y_prob_logreg)\n",
    "logreg_result[\"CV ROC-AUC\"] = roc_auc_score(y_train, logreg_cv_pred)\n",
    "\n",
    "all_results.append(logreg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd42879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model A (NO EARLY STOPPING) for CV\n",
    "xgb_cv = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Generate cross-validation predictions\n",
    "xgb_cv_pred = cross_val_predict(\n",
    "    xgb_cv, X_train, y_train,\n",
    "    cv=cv, method=\"predict_proba\"\n",
    ")[:, 1]\n",
    "\n",
    "\n",
    "# Model B (WITH early stopping) for final test evaluation\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    early_stopping_rounds=30,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_result = evaluate_model(\"XGBoost (CV + ES)\", y_test, y_prob_xgb)\n",
    "xgb_result[\"CV ROC-AUC\"] = roc_auc_score(y_train, xgb_cv_pred)\n",
    "\n",
    "all_results.append(xgb_result)\n",
    "\n",
    "xgb_importance = xgb.feature_importances_\n",
    "\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"importance\": xgb_importance\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Escape $ to avoid LaTeX rendering errors\n",
    "feat_imp_df[\"feature\"] = feat_imp_df[\"feature\"].str.replace(\"$\", \"\\\\$\")\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.barh(feat_imp_df.head(20)[\"feature\"], feat_imp_df.head(20)[\"importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"XGBoost Feature Importance (Top 20)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. NEURAL NETWORK (MLP) (finetune and get SHAP)\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=80,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV predictions\n",
    "mlp_cv_pred = cross_val_predict(\n",
    "    mlp_pipeline, X_train, y_train,\n",
    "    cv=cv, method=\"predict_proba\"\n",
    ")[:, 1]\n",
    "\n",
    "# Train on full training set\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_prob_mlp = mlp_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mlp_result = evaluate_model(\"Neural Network (MLP CV)\", y_test, y_prob_mlp)\n",
    "mlp_result[\"CV ROC-AUC\"] = roc_auc_score(y_train, mlp_cv_pred)\n",
    "\n",
    "all_results.append(mlp_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 7. RESULTS SUMMARY\n",
    "# ====================================================\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
